{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "FEATURES = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "class Point(object):\n",
    "    \"\"\"\n",
    "    Represents a data point\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features):\n",
    "        \"\"\"\n",
    "        Initialize attributes\n",
    "        \"\"\"\n",
    "        if type(features) == np.ndarray:\n",
    "            self.features = features\n",
    "            self.descriptors = None\n",
    "        else:\n",
    "            self.features = np.array(features[FEATURES])\n",
    "            self.descriptors = np.array(features.drop(FEATURES))\n",
    "\n",
    "    def dimensionality(self):\n",
    "        \"\"\"Returns dimension of the point\"\"\"\n",
    "        return len(self.features)\n",
    "    \n",
    "    def get_position(self):\n",
    "        return self.features\n",
    "\n",
    "    def get_features(self):\n",
    "        \"\"\"Returns features\"\"\"\n",
    "        if self.descriptors is not None:\n",
    "            return np.array(list(self.features) + list(self.descriptors))\n",
    "        else:\n",
    "            return np.array(self.features)\n",
    "\n",
    "    def distance(self, other):\n",
    "        \"\"\"\n",
    "        other: point, to which we are measuring distance to\n",
    "        Return Euclidean distance of this point with other\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(np.subtract(np.array(self.features),np.array(other.features)))\n",
    "\n",
    "class Cluster(object):\n",
    "    \"\"\"\n",
    "    A Cluster is defined as a set of elements\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, centroid):\n",
    "        \"\"\"\n",
    "        Elements of a cluster are saved in a list, self.points\n",
    "        \"\"\"\n",
    "        self.points = []\n",
    "        self.centroid = Point(centroid)\n",
    "\n",
    "    def add_point(self, point):\n",
    "        \"\"\"Adds a point to the cluster\"\"\"\n",
    "        self.points.append(point)\n",
    "\n",
    "    def get_points(self):\n",
    "        \"\"\"Returns points in the cluster as a list\"\"\"\n",
    "        return self.points\n",
    "    \n",
    "    def update(self, new_mean):\n",
    "        \"\"\"\n",
    "        new_mean: the new centroid \n",
    "        Updates a cluster mean\n",
    "        \"\"\"\n",
    "        self.centroid = Point(np.array(new_mean))\n",
    "\n",
    "class ClusterSet(object):\n",
    "    \"\"\"\n",
    "    A ClusterSet is defined as a list of clusters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize an empty set, without any clusters\n",
    "        \"\"\"\n",
    "        self.clusters = []\n",
    "\n",
    "    def add(self, c):\n",
    "        \"\"\"\n",
    "        c: Cluster\n",
    "        Appends a cluster c to the end of the cluster list\n",
    "        only if it doesn't already exist in the ClusterSet.\n",
    "        If it is already in self.clusters, raise a ValueError\n",
    "        \"\"\"\n",
    "        if c in self.clusters:\n",
    "            raise ValueError\n",
    "        self.clusters.append(c)\n",
    "        \n",
    "\n",
    "    def get_clusters(self):\n",
    "        \"\"\"Returns clusters in the ClusterSet\"\"\"\n",
    "        return self.clusters[:]\n",
    "\n",
    "    def get_centroids(self):\n",
    "        \"\"\"Returns centroids of each cluster in the ClusterSet as a list\"\"\"\n",
    "        return [cluster.centroid for cluster in self.get_clusters()]\n",
    "\n",
    "    def distortion(self):\n",
    "        \"\"\"\n",
    "        Distortion is the average of the squared distances from centroids to their points.\n",
    "        It uses the euclidean distance \n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for cluster in self.clusters:\n",
    "            centroid = cluster.centroid\n",
    "            points = cluster.get_points()\n",
    "            distance = 0\n",
    "            for point in points:\n",
    "                distance += point.distance(centroid)**2\n",
    "            distances.append(distance)\n",
    "        \n",
    "        # we have a problem where a lot of clusters get 0 points\n",
    "        # dont count these\n",
    "        return sum(distances)/(len(distances) - distances.count(0))\n",
    "            \n",
    "    def num_clusters(self):\n",
    "        \"\"\"Returns number of clusters in the ClusterSet\"\"\"\n",
    "        return len(self.clusters)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        loss = 0\n",
    "        clusters = self.clusters\n",
    "        centroids = self.get_centroids()\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            points = cluster.get_points()\n",
    "            for point in points:\n",
    "                loss += sum((point.get_features() - centroids[i].get_features())**2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "special-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from operator import methodcaller\n",
    "\n",
    "def closest_centroid(centroids, point):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        centroids: list of all centroids (list of points)\n",
    "        point: the single point to determine closest to\n",
    "    \"\"\"\n",
    "    distances = [centroid.distance(point) for centroid in centroids]\n",
    "    return distances.index(min(distances))\n",
    "    \n",
    "\n",
    "def random_init(df, k, sample):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        df: a dataframe of all the tracks\n",
    "        k: Number of initial centroids\n",
    "        sample: method to sample. None is uniform, otherwise it will be normal\n",
    "    Returns:\n",
    "        List of k unique points randomly selected point ranges\n",
    "    \"\"\"\n",
    "    \n",
    "    if sample is None:\n",
    "        return np.random.uniform(low=df.min(), high=df.max(), size=(k,df.shape[1]))\n",
    "    else:\n",
    "        return np.random.normal(loc=df.mean(), scale=df.std(), size=(k,df.shape[1]))\n",
    "\n",
    "\n",
    "def plot_loss(losses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(list(range(len(losses))), losses, '--', color='tab:blue', label='losses')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    title = f'Minimum Loss: {losses[-1]}'\n",
    "    plt.title(title)\n",
    "    # display the plot\n",
    "    plt.show()\n",
    "\n",
    "def sequential_k_means(df, k, divisor=None, sample=None):\n",
    "    \"\"\"\n",
    "    Clusters points into k clusters using k_means clustering.\n",
    "    Arguments:\n",
    "        df: dataframe containing data for all the tracks\n",
    "        k: the number of clusters\n",
    "        init: The method of initialization. One of ['random', 'kpp'].\n",
    "              If init='kpp', use k_means_pp_init to initialize clusters.\n",
    "              If init='random', use random_init to initialize clusters.\n",
    "              Default value 'random'.\n",
    "    Returns:\n",
    "        Instance of ClusterSet with k clusters\n",
    "    Reference: https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm\n",
    "    \"\"\"\n",
    "    initial_centroids = random_init(df[FEATURES], k, sample)\n",
    "\n",
    "    # fill cluster set\n",
    "    cs = ClusterSet()\n",
    "    for centroid in initial_centroids:\n",
    "        cs.add(Cluster(np.array(centroid)))\n",
    "\n",
    "    centroids_features = [centroid.get_features() for centroid in cs.get_centroids()]\n",
    "    centroids_points = cs.get_centroids()\n",
    "        \n",
    "    # sequential K-means converges when we have gone through all points, unlike regular k means which \n",
    "    # converges when the cluster assignments or means do not change between iterations.\n",
    "    for i in range(df.shape[0]):\n",
    "        # Find centroid that is closest to point i\n",
    "        centroid_index = closest_centroid(centroids_points, Point(df.iloc[i,:]))\n",
    "        # add point to cluster\n",
    "        cs.get_clusters()[centroid_index].add_point(Point(df.iloc[i, :]))\n",
    "        # Update centroid\n",
    "        # can also consider different updates besides 1/n such as a constant shift\n",
    "        prev_mean = centroids_features[centroid_index]\n",
    "        if divisor is None:\n",
    "            new_mean = prev_mean + (1/len(cs.get_clusters()[centroid_index].points))*(df.iloc[i,:][FEATURES] - prev_mean)\n",
    "        else:\n",
    "            # constant divisor\n",
    "            new_mean = prev_mean + (1/divisor)*(df.iloc[i,:][FEATURES] - prev_mean)\n",
    "        cs.get_clusters()[centroid_index].update(new_mean)\n",
    "        \n",
    "        \n",
    "    # calculate distortion\n",
    "    distortion = cs.distortion()\n",
    "        # calculate loss\n",
    "#         distances = np.round(pairwise_distances(\n",
    "#             [centroid.get_features() for centroid in new_cs.get_centroids()],\n",
    "#             [p.get_features() for p in points]), 3)\n",
    "#         loss_iter = new_cs.get_loss()\n",
    "#         losses.append(loss_iter)\n",
    "#         print(f'----Loss: {loss_iter}----')\n",
    "    \n",
    "#     plot_loss(losses)\n",
    "#     score = prev_cs.get_score()\n",
    "#     loss = prev_cs.get_loss()\n",
    "#     centroids = prev_cs.get_centroids()\n",
    "#     sizes = [len(cluster.get_points()) for cluster in prev_cs.get_clusters()]\n",
    "\n",
    "    centroids = cs.get_centroids()\n",
    "    clusters = cs.get_clusters()\n",
    "    sizes = [len(cluster.get_points()) for cluster in cs.get_clusters()]\n",
    "    \n",
    "    return [centroids, sizes, clusters, distortion]\n",
    "    return [score, loss, centroids, sizes]\n",
    "\n",
    "def plot_performance(sequential_k_means_scores, k_vals, percent_empty):\n",
    "    \"\"\"\n",
    "    Uses matplotlib to generate a graph of performance vs. k\n",
    "    Arguments:\n",
    "        sequential_k_means_scores: A list of len(k_vals) average distortion scores from\n",
    "            running the k-means algorithm with random initialization\n",
    "        k_vals: A list of integer k values used to calculate the above scores\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.subplots()\n",
    "    ax1.plot(k_vals, sequential_k_means_scores, '--', color='tab:blue', label='distortion')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(k_vals, percent_empty, '--', color='tab:orange', label='% empty')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.xlabel('Number of Clusters, k')\n",
    "#     plt.ylabel('Distortion')\n",
    "\n",
    "    # display the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
